{
    "link": "https://blackdotresearch.sg/the-story-so-far-on-the-deepnudeapp-scandal/",
    "Title": "\n\t\t\t\t\t\t\t\t\t\t\t[The Story So Far]: On the deepnudeapp scandal\t\t\t\t\t\t\t\t\t\t  \t\t\t\t\t\t\t\t\n",
    "Tags": [],
    "Paragraphs": "\n\nYou may have heard something about the \u201cdeepnudeapp\u201d (the \u201cApp\u201c).\u00a0 The App is a computer software that has the ability to make photographs of women (and only women) appear naked.\nAccording to various online reports, the App is a recent creation (written a number of months ago) which was launched on a website that permitted downloading on to Windows and Linux platforms for a fee.\u00a0 Apparently, the App was created in Estonia and sold at US$50 a copy. \u00a0In a recent June 2019 article by Vice media, one of the App\u2019s creators (who remained anonymous by using \u201cAlberto\u201d as a pseudonym) had this to say:\n\u201cI\u2019m not a voyeur, I\u2019m a technology enthusiast,\u2026 Continuing to improve the algorithm. Recently, also due to previous failures (other startups) and economic problems, I asked myself if I could have an economic return from this algorithm. That\u2019s why I created DeepNude.\u201c\nUnprompted, he said he\u2019s always asked himself whether the program should have ever been made: \u201cIs this right? Can it hurt someone?\u201d he asked.\n\u201cI think that what you can do with DeepNude, you can do it very well with Photoshop (after a few hours of tutorial),\u201d he said, noting that DeepNude doesn\u2019t transmit images itself, only creates them and allows the user to do what they will with the results.\n\u201cI also said to myself: the technology is ready (within everyone\u2019s reach),\u201d he said. \u201cSo if someone has bad intentions, having DeepNude doesn\u2019t change much\u2026 If I don\u2019t do it, someone else will do it in a year.\u201c\nOn 27 June 2019, after the article was published, the deepnudeapp was taken down.\u00a0 Its creators stated, in a Twitter post:\n\npic.twitter.com/8uJKBQTZ0o\n\u2014 deepnudeapp (@deepnudeapp) June 27, 2019\n\nSee the Vice article reporting on the removal of the App here.\u00a0 The creators apparently mentioned that they had greatly underestimated the demand for the App, and also never thought that it could go viral.\nReally? That\u2019s a little hard to believe.\nAs reported today in The New Paper (10 July 2019), the terrifying possibilities posed by the App have reached Singapore.\u00a0 According to the report, several App photos of various local female victims have been circulating, prompting some to completely privatise their social media accounts to prevent further access to their photos.\u00a0 It is unclear how many are presently affected and whether all the victims are aware of the ongoing circulation of their manipulated pictures.\nHow does the App work?\nFirst, keep in mind that the creator may have taken down the App officially, but the App remains in circulation on the web and can easily be obtained.\u00a0 We have personally trawled the web and come across various links offering the App.\nAccording to an online source, the App works by taking 3 steps \u2013 First, with the picture that it has, the App creates a mask over the figure of the female subject.\u00a0 Next, it generates an abstract representation of the body shape, anticipating where the various body parts will be and their angles. Third, it searches for existing pictures of such body parts and composites the images on to the mask and then generates the fake nude photo.\n\nThe above screenshot shows how the core algorithm of the App generates a deepnude photo.\u00a0 Apparently, the creators chose to limit the App to women because naked pictures of women were easier to find online to comprise the bank of pictures the App needs.\nPresently a normal computer (we assume this means a home computer) can process a deepnude photo on the App in approximately 30 seconds.\nAs we understand from various other reports, the process and algorithm adopted by the App is closely similar to the way deepfake photos and videos are being generated.\u00a0 This is another variant, perhaps better regarded as an evolution of the deepfake software.\nThe effects and what can be done \u2013 in Singapore\nAcross the world, deep outrage has been expressed at what the App can do.\nWe note that the earlier cited 27 June 2019 Vice article engaged in some self-censorship to minimise the harm that could be caused as a result of misusing the App.\u00a0 As Vice states:\n\u201cEditor\u2019s note, June 27 1:05 p.m. EST: This story originally included five side-by-side images of various celebrities and DeepNude-manipulated images of those celebrities. While the images were redacted to not show explicit nudity, after hearing from our readers, academic experts, and colleagues, we realized that those images could do harm to the real people in them. We think it\u2019s important to show the real consequences that new technologies unleashed on the world without warning have on people, but we also have to make sure that our reporting minimizes harm. For that reason, we have removed the images from the story, and regret the error.\u201d\nQuite plainly, the harm that could be caused is psychological and reputational, amongst potentially many other types of harm.\nA quick review of various statutes in Singapore indicate that using the App to create a deepnude of a woman, intending that the final product be circulated is very likely illegal, and a single act appears to \u00a0possibly lead to the commission of several offences, such as the following:\n\nCriminal defamation under the Penal Code:\n\nUnder Section 499 of the Penal Code: 499.\u00a0\u00a0Whoever, by words either spoken or intended to be read, or by signs, or by visible representations, makes or publishes any imputation concerning any person, intending to harm, or knowing or having reason to believe that such imputation will harm, the reputation of such person, is said, except in the cases hereinafter excepted, to defame that person.\nExplanation 4.\u2014No imputation is said to harm a person\u2019s reputation, unless that imputation directly or indirectly, in the estimation of others, lowers the moral or intellectual character of that person, or lowers the character of that person in respect of his calling, or lowers the credit of that person, or causes it to be believed that the body of that person is in a loathsome state, or in a state generally considered as disgraceful.\nThis is punishable with imprisonment for a term which may extend to 2 years or with fine, or both.\n\n\nHarassment under the Protection from Harassment Act:\n\nSections 3 and 4 of the Protection from Harassment Act plausibly make criminal the act of communicating an image, or a visual representation (this could well include a deepnude photograph) either with the intention of causing harassment, alarm or distress to the victim (Section 3), or such image is seen or perceived by someone else and thereby causes such harassment, alarm or distress (Section 4).\nSection 3.\u2014(1)\u00a0\u00a0No person shall, with intent to cause harassment, alarm or distress to another person, by any means \u2014\n\n\n\n(a)\u00a0 use any threatening, abusive or insulting words or behaviour; or\n(b) make any threatening, abusive or insulting communication,\nthereby causing that other person or any other person (each referred to for the purposes of this section as the victim) harassment, alarm or distress.\n\n\n\nSection 4.\u2014(1)\u00a0\u00a0No person shall by any means\u00a0\u2014\n\n\n\n(a) use any threatening, abusive or insulting words or behaviour; or\n(b) make any threatening, abusive or insulting communication,\nwhich is heard, seen or otherwise perceived by any person (referred to for the purposes of this section as the victim) likely to be caused harassment, alarm or distress.\n\n\n\nPunishment-wise, under Section 3, this is with a fine of up to S$5,000 or to imprisonment for a term not exceeding 6 months, or both.\u00a0 Under Section 4, only with a fine of up to S$5,000.\n\n\nUndesirable Publications Act\n\nUnder Section 11 of the Undesirable Publications Act: Any person who\u00a0\u2014\n\n\n\n(a) makes or reproduces, or makes or reproduces for the purposes of sale, supply, exhibition or distribution to any other person;\n(b) imports or has in his possession for the purposes of sale, supply, exhibition or distribution to any other person; or\n(c) sells, offers for sale, supplies, offers to supply, exhibits or distributes to any other person,\nany obscene publication (not being a prohibited publication) knowing or having reasonable cause to believe the publication to be obscene shall be guilty of an offence and shall be liable on conviction to a fine not exceeding $10,000 or to imprisonment for a term not exceeding 2 years or to both.\nWe note that criminal offences are in the realm of the Police and the Attorney General\u2019s Chambers, and there is little more that can be done once a police report is made. We also stress that the authorities may not agree with us on what constitutes criminal conduct.\nHowever, we would emphasise that a victim may be able to take out proceedings herself under the latest Protection From Harassment Act.\nUnder Section 15 of the Protection From Harassment Act, a victim can apply to the District Court for an order to cease publication or take down the photograph from online sites.\u00a0 Whether an application will be successful however, is hard to say.\u00a0 It depends on whether the term \u201cstatement\u201d includes visual representations and photographs made by the App.\u00a0 We believe that the grounds for success are strong \u2013 It is difficult to believe that the statute intended for \u201cstatement\u201d to be limited to words alone.\u00a0 A statement can be conveyed in a variety of ways, not necessarily in writing. If we would consider an audio recording that is distributed to be sufficient to trigger the remedies under the Act, then why not a picture?\n\n",
    "Image Sources": "https://blackdotresearch.sg/wp-content/uploads/2019/07/Screenshot-2019-07-10-at-5.07.31-PM.png",
    "Iframe Sources": [],
    "date": "2019-07-10T10:24:31+00:00",
    "Links in content": [
        "https://www.vice.com/en_us/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman",
        "https://t.co/8uJKBQTZ0o",
        "https://twitter.com/deepnudeapp/status/1144307316231200768?ref_src=twsrc%5Etfw",
        "https://www.vice.com/en_us/article/qv7agw/deepnude-app-that-undresses-photos-of-women-takes-it-offline",
        "https://www.asiaone.com/singapore/singapore-women-fall-victim-deepnude-app"
    ],
    "Author": "Faizal Kamal",
    "banner": "https://blackdotresearch.sg/wp-content/uploads/2019/07/Screenshot-2019-07-10-at-5.07.31-PM.png",
    "Truefalse": [],
    "Description": ""
}